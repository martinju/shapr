<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Explain the Output of Machine Learning Models with more Accurately Estimated Shapley Values • shapr</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="bootstrap-toc.css">
<script src="bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="pkgdown.css" rel="stylesheet">
<script src="pkgdown.js"></script><meta property="og:title" content="Explain the Output of Machine Learning Models with more Accurately Estimated Shapley Values">
<meta property="og:description" content="Complex machine learning models are often hard to interpret. However, in 
  many situations it is crucial to understand and explain why a model made a specific 
  prediction. Shapley values is the only method for such prediction explanation framework 
  with a solid theoretical foundation. Previously known methods for estimating the Shapley 
  values do, however, assume feature independence. This package implements the method 
  described in Aas, Jullum and Løland (2019) &lt;arXiv:1903.10464&gt;, which accounts for any feature 
  dependence, and thereby produces more accurate estimates of the true Shapley values.">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-home">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="index.html">shapr</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.1.1</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="articles/understanding_shapr.html">`shapr`: Explaining individual machine learning predictions with Shapley values</a>
    </li>
  </ul>
</li>
<li>
  <a href="news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/NorskRegnesentral/shapr/">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="contents col-md-9">
<div id="shapr-" class="section level1">
<div class="page-header"><h1 class="hasAnchor">
<a href="#shapr-" class="anchor"></a>shapr <img src="reference/figures/NR-logo_utvidet_r32g60b136_small.png" align="right" height="50px">
</h1></div>
<!-- badges: start -->

<p>The most common task of machine learning is to train a model which is able to predict an unknown outcome (response variable) based on a set of known input variables/features. When using such models for real life applications, it is often crucial to understand why a certain set of features lead to exactly that prediction. However, explaining predictions from complex, or seemingly simple, machine learning models is a practical and ethical question, as well as a legal issue. Can I trust the model? Is it biased? Can I explain it to others? We want to explain individual predictions from a complex machine learning model by learning simple, interpretable explanations.</p>
<p>Shapley values is the only prediction explanation framework with a solid theoretical foundation (Lundberg and Lee (2017)). Unless the true distribution of the features are known, and there are less than say 10-15 features, these Shapley values needs to be estimated/approximated. Popular methods like Shapley Sampling Values (Štrumbelj and Kononenko (2014)), SHAP/Kernel SHAP (Lundberg and Lee (2017)), and to some extent TreeSHAP (Lundberg, Erion, and Lee (2018)), assume that the features are independent when approximating the Shapley values for prediction explanation. This may lead to very inaccurate Shapley values, and consequently wrong interpretations of the predictions. Aas, Jullum, and Løland (2019) extends and improves the Kernel SHAP method of Lundberg and Lee (2017) to account for the dependence between the features, resulting in significantly more accurate approximations to the Shapley values. <a href="https://arxiv.org/abs/1903.10464">See the paper for details</a>.</p>
<p>This package implements the methodology of Aas, Jullum, and Løland (2019).</p>
<p>The following methodology/features are currently implemented:</p>
<ul>
<li>Native support of explanation of predictions from models fitted with the following functions <code><a href="https://rdrr.io/r/stats/glm.html">stats::glm</a></code>, <code><a href="https://rdrr.io/r/stats/lm.html">stats::lm</a></code>,<code><a href="https://rdrr.io/pkg/ranger/man/ranger.html">ranger::ranger</a></code>, <code><a href="https://rdrr.io/pkg/xgboost/man/xgb.train.html">xgboost::xgboost</a></code>/<code><a href="https://rdrr.io/pkg/xgboost/man/xgb.train.html">xgboost::xgb.train</a></code> and <code><a href="https://rdrr.io/pkg/mgcv/man/gam.html">mgcv::gam</a></code>.</li>
<li>Accounting for feature dependence assuming the features are Gaussian (Aas, Jullum, and Løland (2019)).</li>
<li>Accounting for feature dependence with a Gaussian copula (Gaussian dependence structure, any marginal) (Aas, Jullum, and Løland (2019)).</li>
<li>Accounting for feature dependence using the Mahalanobis distance based empirical (conditional) distribution approach of Aas, Jullum, and Løland (2019).</li>
<li>Combine any of the three methods.</li>
<li>Optional use of the AICc criterion of Hurvich, Simonoff, and Tsai
(1998) when optimizing the bandwidth parameter in the empirical (conditional) approach of Aas, Jullum, and Løland (2019).</li>
<li>Functionality for visualizing the explanations.</li>
<li>Support for models not supported natively.</li>
</ul>
<!--
Current methodological restrictions:

- The features must follow a continuous distribution
- Discrete features typically work just fine in practice although the theory breaks down
- Ordered/unordered categorical features are not supported
--><p>Future releases will include:</p>
<ul>
<li>Support for parallelization over explanations, Monte Carlo sampling and features subsets for non-parallelizable prediction functions.</li>
<li>Computational improvement of the AICc optimization approach</li>
<li>Adaptive selection of method to account for the feature dependence</li>
</ul>
<p>Note that both the features and the prediction must be numeric. The approach is constructed for continuous features. Discrete features may also work just fine with the empirical (conditional) distribution approach. Unlike SHAP and TreeSHAP, we decompose probability predictions directly to ease the interpretability, i.e. not via log odds transformations. The application programming interface (API) of <code>shapr</code> is inspired by Pedersen and Benesty (2019).</p>
<div id="installation" class="section level2">
<h2 class="hasAnchor">
<a href="#installation" class="anchor"></a>Installation</h2>
<p>To install the current development version, use</p>
<div class="sourceCode" id="cb1"><pre class="downlit">
<span class="kw">devtools</span>::<span class="fu">install_github</span>(<span class="st">"NorskRegnesentral/shapr"</span>)
</pre></div>
<p>If you would like to install all packages of the models we currently support, use</p>
<div class="sourceCode" id="cb2"><pre class="downlit">
<span class="kw">devtools</span>::<span class="fu">install_github</span>(<span class="st">"NorskRegnesentral/shapr"</span>, dependencies = <span class="fl">TRUE</span>)
</pre></div>
<p>If you would also like to build and view the vignette locally, use</p>
<div class="sourceCode" id="cb3"><pre class="downlit">
<span class="kw">devtools</span>::<span class="fu">install_github</span>(<span class="st">"NorskRegnesentral/shapr"</span>, dependencies = <span class="fl">TRUE</span>, build_vignettes = <span class="fl">TRUE</span>)
<span class="fu"><a href="https://rdrr.io/r/utils/vignette.html">vignette</a></span>(<span class="st">"understanding_shapr"</span>, <span class="st">"shapr"</span>)
</pre></div>
<p>You can always check out the latest version of the vignette <a href="https://norskregnesentral.github.io/shapr/articles/understanding_shapr.html">here</a>.</p>
</div>
<div id="example" class="section level2">
<h2 class="hasAnchor">
<a href="#example" class="anchor"></a>Example</h2>
<p><code>shapr</code> supports computation of Shapley values with any predictive model which takes a set of numeric features and produces a numeric outcome.</p>
<p>The following example shows how a simple <code>xgboost</code> model is trained using the <em>Boston Housing Data</em>, and how <code>shapr</code> explains the individual predictions.</p>
<div class="sourceCode" id="cb4"><pre class="downlit">
<span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="kw"><a href="https://github.com/dmlc/xgboost">xgboost</a></span>)
<span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="kw"><a href="https://norskregnesentral.github.io/shapr">shapr</a></span>)

<span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span>(<span class="st">"Boston"</span>, package = <span class="st">"MASS"</span>)

<span class="kw">x_var</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"lstat"</span>, <span class="st">"rm"</span>, <span class="st">"dis"</span>, <span class="st">"indus"</span>)
<span class="kw">y_var</span> <span class="op">&lt;-</span> <span class="st">"medv"</span>

<span class="kw">ind_x_test</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="fl">6</span>
<span class="kw">x_train</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span>(<span class="kw">Boston</span>[<span class="op">-</span><span class="kw">ind_x_test</span>, <span class="kw">x_var</span>])
<span class="kw">y_train</span> <span class="op">&lt;-</span> <span class="kw">Boston</span>[<span class="op">-</span><span class="kw">ind_x_test</span>, <span class="kw">y_var</span>]
<span class="kw">x_test</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span>(<span class="kw">Boston</span>[<span class="kw">ind_x_test</span>, <span class="kw">x_var</span>])

<span class="co"># Looking at the dependence between the features</span>
<span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span>(<span class="kw">x_train</span>)
<span class="co">#&gt;            lstat         rm        dis      indus</span>
<span class="co">#&gt; lstat  1.0000000 -0.6108040 -0.4928126  0.5986263</span>
<span class="co">#&gt; rm    -0.6108040  1.0000000  0.1999130 -0.3870571</span>
<span class="co">#&gt; dis   -0.4928126  0.1999130  1.0000000 -0.7060903</span>
<span class="co">#&gt; indus  0.5986263 -0.3870571 -0.7060903  1.0000000</span>

<span class="co"># Fitting a basic xgboost model to the training data</span>
<span class="kw">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/xgboost/man/xgb.train.html">xgboost</a></span>(
  data = <span class="kw">x_train</span>,
  label = <span class="kw">y_train</span>,
  nround = <span class="fl">20</span>,
  verbose = <span class="fl">FALSE</span>
)

<span class="co"># Prepare the data for explanation</span>
<span class="kw">explainer</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/shapr.html">shapr</a></span>(<span class="kw">x_train</span>, <span class="kw">model</span>)

<span class="co"># Specifying the phi_0, i.e. the expected prediction without any features</span>
<span class="kw">p</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span>(<span class="kw">y_train</span>)

<span class="co"># Computing the actual Shapley values with kernelSHAP accounting for feature dependence using</span>
<span class="co"># the empirical (conditional) distribution approach with bandwidth parameter sigma = 0.1 (default)</span>
<span class="kw">explanation</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/explain.html">explain</a></span>(
  <span class="kw">x_test</span>,
  approach = <span class="st">"empirical"</span>,
  explainer = <span class="kw">explainer</span>,
  prediction_zero = <span class="kw">p</span>
)

<span class="co"># Printing the Shapley values for the test data.</span>
<span class="co"># For more information about the interpretation of the values in the table, see ?shapr::explain.</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span>(<span class="kw">explanation</span><span class="op">$</span><span class="kw">dt</span>)
<span class="co">#&gt;      none     lstat         rm       dis      indus</span>
<span class="co">#&gt; 1: 22.446 5.2632030 -1.2526613 0.2920444  4.5528644</span>
<span class="co">#&gt; 2: 22.446 0.1671903 -0.7088405 0.9689007  0.3786871</span>
<span class="co">#&gt; 3: 22.446 5.9888016  5.5450861 0.5660136 -1.4304350</span>
<span class="co">#&gt; 4: 22.446 8.2142203  0.7507569 0.1893368  1.8298305</span>
<span class="co">#&gt; 5: 22.446 0.5059890  5.6875106 0.8432240  2.2471152</span>
<span class="co">#&gt; 6: 22.446 1.9929674 -3.6001959 0.8601984  3.1510531</span>

<span class="co"># Finally we plot the resulting explanations</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span>(<span class="kw">explanation</span>)
</pre></div>
<p><img src="reference/figures/README-basic_example-1.png" width="100%"></p>
</div>
<div id="contribution" class="section level2">
<h2 class="hasAnchor">
<a href="#contribution" class="anchor"></a>Contribution</h2>
<p>All feedback and suggestions are very welcome. Details on how to contribute can be found <a href="./CONTRIBUTING.html">here</a>. If you have any questions or comments, feel free to open an issue <a href="https://github.com/NorskRegnesentral/shapr/issues">here</a>.</p>
<p>Please note that the ‘shapr’ project is released with a <a href="CODE_OF_CONDUCT.html">Contributor Code of Conduct</a>. By contributing to this project, you agree to abide by its terms.</p>
</div>
<div id="references" class="section level2">
<h2 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h2>
<div id="refs" class="references hanging-indent">
<div id="ref-aas2019explaining">
<p>Aas, Kjersti, Martin Jullum, and Anders Løland. 2019. “Explaining Individual Predictions When Features Are Dependent: More Accurate Approximations to Shapley Values.” <em>arXiv Preprint arXiv:1903.10464</em>.</p>
</div>
<div id="ref-hurvich1998smoothing">
<p>Hurvich, Clifford M, Jeffrey S Simonoff, and Chih-Ling Tsai. 1998. “Smoothing Parameter Selection in Nonparametric Regression Using an Improved Akaike Information Criterion.” <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 60 (2): 271–93.</p>
</div>
<div id="ref-lundberg2018consistent">
<p>Lundberg, Scott M, Gabriel G Erion, and Su-In Lee. 2018. “Consistent Individualized Feature Attribution for Tree Ensembles.” <em>arXiv Preprint arXiv:1802.03888</em>.</p>
</div>
<div id="ref-lundberg2017unified">
<p>Lundberg, Scott M, and Su-In Lee. 2017. “A Unified Approach to Interpreting Model Predictions.” In <em>Advances in Neural Information Processing Systems</em>, 4765–74.</p>
</div>
<div id="ref-lime_api">
<p>Pedersen, Thomas Lin, and Michaël Benesty. 2019. <em>Lime: Local Interpretable Model-Agnostic Explanations</em>. <a href="https://CRAN.R-project.org/package=lime" class="uri">https://CRAN.R-project.org/package=lime</a>.</p>
</div>
<div id="ref-vstrumbelj2014explaining">
<p>Štrumbelj, Erik, and Igor Kononenko. 2014. “Explaining Prediction Models and Individual Predictions with Feature Contributions.” <em>Knowledge and Information Systems</em> 41 (3): 647–65.</p>
</div>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <div class="links">
<h2>Links</h2>
<ul class="list-unstyled">
<li>Browse source code at <br><a href="https://github.com/NorskRegnesentral/shapr/">https://​github.com/​NorskRegnesentral/​shapr/​</a>
</li>
<li>Report a bug at <br><a href="https://github.com/NorskRegnesentral/shapr/issues">https://​github.com/​NorskRegnesentral/​shapr/​issues</a>
</li>
</ul>
</div>
<div class="license">
<h2>License</h2>
<ul class="list-unstyled">
<li><a href="LICENSE.html">Full license</a></li>
<li><small><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file <a href="LICENSE-text.html">LICENSE</a></small></li>
</ul>
</div>
<div class="community">
<h2>Community</h2>
<ul class="list-unstyled">
<li><a href="CONTRIBUTING.html">Contributing guide</a></li>
<li><a href="CODE_OF_CONDUCT.html">Code of conduct</a></li>
</ul>
</div>
<div class="developers">
<h2>Developers</h2>
<ul class="list-unstyled">
<li>Nikolai Sellereite <br><small class="roles"> Maintainer, author </small> <a href="https://orcid.org/0000-0002-4671-0337" target="orcid.widget" aria-label="ORCID"><span class="fab fa-orcid orcid" aria-hidden="true"></span></a> </li>
<li>Martin Jullum <br><small class="roles"> Author </small> <a href="https://orcid.org/0000-0003-3908-5155" target="orcid.widget" aria-label="ORCID"><span class="fab fa-orcid orcid" aria-hidden="true"></span></a> </li>
<li><a href="authors.html">All authors...</a></li>
</ul>
</div>

  <div class="dev-status">
<h2>Dev status</h2>
<ul class="list-unstyled">
<li><a href="https://github.com/NorskRegnesentral/shapr/actions?query=workflow%3AR-CMD-check"><img src="https://github.com/NorskRegnesentral/shapr/workflows/R-CMD-check/badge.svg" alt="R build status"></a></li>
<li><a href="https://www.tidyverse.org/lifecycle/#experimental"><img src="https://img.shields.io/badge/lifecycle-experimental-orange.svg" alt="Lifecycle: experimental"></a></li>
<li><a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT"></a></li>
<li><a href="https://doi.org/10.21105/joss.02027"><img src="https://joss.theoj.org/papers/10.21105/joss.02027/status.svg" alt="DOI"></a></li>
</ul>
</div>
</div>
</div>


      <footer><div class="copyright">
  <p>Developed by Nikolai Sellereite, Martin Jullum.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.5.1.9000.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
